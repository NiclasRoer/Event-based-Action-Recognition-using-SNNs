{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMU/h8k4Cke1YbFjIYVLLie",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NiclasRoer/Event-based-Action-Recognition-using-SNNs/blob/main/SNN_on_MNIST_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snntorch --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAAo2K18wJpd",
        "outputId": "43bd1c1d-7c04-4083-e7de-e90c87262324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 30 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 40 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 95 kB 2.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z77nz4y9v8kv"
      },
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import utils \n",
        "from snntorch import backprop\n",
        "import snntorch.functional as SF\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "data_path='/data/mnist'\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "beta = 0.9  # neuron decay rate \n",
        "spike_grad = surrogate.fast_sigmoid()\n",
        "\n",
        "#  Initialize Network\n",
        "net = nn.Sequential(nn.Conv2d(1, 8, 5),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.Conv2d(8, 16, 5),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.Flatten(),\n",
        "                    nn.Linear(16*4*4, 10),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
        "                    ).to(device)\n",
        "\n",
        "\n",
        "def forward_pass(net, data, num_steps):  \n",
        "  spk_rec = []\n",
        "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
        "\n",
        "  for step in range(num_steps): \n",
        "      spk_out, mem_out = net(data)\n",
        "      spk_rec.append(spk_out)\n",
        "  \n",
        "  return torch.stack(spk_rec)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=2e-3, betas=(0.9, 0.999))\n",
        "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
        "\n",
        "num_epochs = 1\n",
        "num_steps = 25  # run for 25 time steps \n",
        "\n",
        "loss_hist = []\n",
        "acc_hist = []\n",
        "\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (data, targets) in enumerate(iter(train_loader)):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        net.train()\n",
        "        spk_rec = forward_pass(net, data, num_steps)\n",
        "        loss_val = loss_fn(spk_rec, targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # print every 25 iterations\n",
        "        if i % 25 == 0:\n",
        "          print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}\")\n",
        "\n",
        "          # check accuracy on a single batch\n",
        "          acc = SF.accuracy_rate(spk_rec, targets)  \n",
        "          acc_hist.append(acc)\n",
        "          print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
        "        \n",
        "        # uncomment for faster termination\n",
        "        # if i == 150:\n",
        "        #     break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJu5IwHSwFyV",
        "outputId": "5e2df958-43a5-41a7-c7a0-cc56a421c25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Iteration 0 \n",
            "Train Loss: 2.22\n",
            "Accuracy: 13.28%\n",
            "\n",
            "Epoch 0, Iteration 25 \n",
            "Train Loss: 0.66\n",
            "Accuracy: 50.00%\n",
            "\n",
            "Epoch 0, Iteration 50 \n",
            "Train Loss: 0.43\n",
            "Accuracy: 82.03%\n",
            "\n",
            "Epoch 0, Iteration 75 \n",
            "Train Loss: 0.33\n",
            "Accuracy: 88.28%\n",
            "\n",
            "Epoch 0, Iteration 100 \n",
            "Train Loss: 0.33\n",
            "Accuracy: 86.72%\n",
            "\n",
            "Epoch 0, Iteration 125 \n",
            "Train Loss: 0.28\n",
            "Accuracy: 91.41%\n",
            "\n",
            "Epoch 0, Iteration 150 \n",
            "Train Loss: 0.25\n",
            "Accuracy: 92.19%\n",
            "\n",
            "Epoch 0, Iteration 175 \n",
            "Train Loss: 0.24\n",
            "Accuracy: 95.31%\n",
            "\n",
            "Epoch 0, Iteration 200 \n",
            "Train Loss: 0.22\n",
            "Accuracy: 96.09%\n",
            "\n",
            "Epoch 0, Iteration 225 \n",
            "Train Loss: 0.24\n",
            "Accuracy: 90.62%\n",
            "\n",
            "Epoch 0, Iteration 250 \n",
            "Train Loss: 0.19\n",
            "Accuracy: 96.09%\n",
            "\n",
            "Epoch 0, Iteration 275 \n",
            "Train Loss: 0.19\n",
            "Accuracy: 96.09%\n",
            "\n",
            "Epoch 0, Iteration 300 \n",
            "Train Loss: 0.17\n",
            "Accuracy: 95.31%\n",
            "\n",
            "Epoch 0, Iteration 325 \n",
            "Train Loss: 0.19\n",
            "Accuracy: 94.53%\n",
            "\n",
            "Epoch 0, Iteration 350 \n",
            "Train Loss: 0.17\n",
            "Accuracy: 97.66%\n",
            "\n",
            "Epoch 0, Iteration 375 \n",
            "Train Loss: 0.21\n",
            "Accuracy: 92.97%\n",
            "\n",
            "Epoch 0, Iteration 400 \n",
            "Train Loss: 0.18\n",
            "Accuracy: 96.09%\n",
            "\n",
            "Epoch 0, Iteration 425 \n",
            "Train Loss: 0.14\n",
            "Accuracy: 97.66%\n",
            "\n",
            "Epoch 0, Iteration 450 \n",
            "Train Loss: 0.17\n",
            "Accuracy: 93.75%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    avg_loss = backprop.BPTT(net, train_loader, num_steps=num_steps,\n",
        "                          optimizer=optimizer, criterion=loss_fn, time_var=False, device=device)\n",
        "\n",
        "    print(f\"Epoch {epoch}, Train Loss: {avg_loss.item():.2f}\")\n",
        "\n",
        "def test_accuracy(data_loader, net, num_steps):\n",
        "  with torch.no_grad():\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    net.eval()\n",
        "\n",
        "    data_loader = iter(data_loader)\n",
        "    for data, targets in data_loader:\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "      spk_rec = forward_pass(net, data, num_steps)\n",
        "\n",
        "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
        "      total += spk_rec.size(1)\n",
        "\n",
        "  return acc/total\n",
        "print(f\"Test set accuracy: {test_accuracy(test_loader, net, num_steps)*100:.3f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v1INffdxVkA",
        "outputId": "daefce5a-f698-42c0-f547-5dc90e4cc40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 0.14\n",
            "Epoch 1, Train Loss: 0.12\n",
            "Epoch 2, Train Loss: 0.11\n",
            "Test set accuracy: 98.170%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Define Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        num_inputs = 784\n",
        "        num_hidden = 300\n",
        "        num_outputs = 10\n",
        "        spike_grad = surrogate.fast_sigmoid()\n",
        "\n",
        "        # global decay rate for all leaky neurons in layer 1\n",
        "        beta1 = 0.9\n",
        "        # independent decay rate for each leaky neuron in layer 2: [0, 1)\n",
        "        beta2 = torch.rand((num_outputs), dtype = torch.float) #.to(device)\n",
        "\n",
        "        # Init layers\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.lif1 = snn.Leaky(beta=beta1, spike_grad=spike_grad, learn_beta=True)\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif2 = snn.Leaky(beta=beta2, spike_grad=spike_grad,learn_beta=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # reset hidden states and outputs at t=0\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x.flatten(1))\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec), torch.stack(mem2_rec)\n",
        "\n",
        "# Load the network onto CUDA if available\n",
        "net = Net().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=2e-3, betas=(0.9, 0.999))\n",
        "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
        "\n",
        "num_epochs = 1\n",
        "num_steps = 100  # run for 25 time steps \n",
        "\n",
        "loss_hist = []\n",
        "acc_hist = []\n",
        "\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (data, targets) in enumerate(iter(train_loader)):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        net.train()\n",
        "        spk_rec, _ = net(data)\n",
        "        loss_val = loss_fn(spk_rec, targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # print every 25 iterations\n",
        "        if i % 25 == 0:\n",
        "          net.eval()\n",
        "          print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}\")\n",
        "\n",
        "          # check accuracy on a single batch\n",
        "          acc = SF.accuracy_rate(spk_rec, targets)  \n",
        "          acc_hist.append(acc)\n",
        "          print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
        "        \n",
        "        # uncomment for faster termination\n",
        "        # if i == 150:\n",
        "        #     break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erN4iFr6xg8-",
        "outputId": "60a60ecf-9de8-40d0-a677-05ba5d93f7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Iteration 0 \n",
            "Train Loss: 10.00\n",
            "Accuracy: 9.38%\n",
            "\n",
            "Epoch 0, Iteration 25 \n",
            "Train Loss: 2.99\n",
            "Accuracy: 79.69%\n",
            "\n",
            "Epoch 0, Iteration 50 \n",
            "Train Loss: 1.60\n",
            "Accuracy: 87.50%\n",
            "\n",
            "Epoch 0, Iteration 75 \n",
            "Train Loss: 1.20\n",
            "Accuracy: 89.84%\n",
            "\n",
            "Epoch 0, Iteration 100 \n",
            "Train Loss: 1.13\n",
            "Accuracy: 90.62%\n",
            "\n",
            "Epoch 0, Iteration 125 \n",
            "Train Loss: 0.83\n",
            "Accuracy: 94.53%\n",
            "\n",
            "Epoch 0, Iteration 150 \n",
            "Train Loss: 0.85\n",
            "Accuracy: 93.75%\n",
            "\n",
            "Epoch 0, Iteration 175 \n",
            "Train Loss: 0.94\n",
            "Accuracy: 92.19%\n",
            "\n",
            "Epoch 0, Iteration 200 \n",
            "Train Loss: 0.72\n",
            "Accuracy: 96.88%\n",
            "\n",
            "Epoch 0, Iteration 225 \n",
            "Train Loss: 0.85\n",
            "Accuracy: 90.62%\n",
            "\n",
            "Epoch 0, Iteration 250 \n",
            "Train Loss: 0.81\n",
            "Accuracy: 94.53%\n",
            "\n",
            "Epoch 0, Iteration 275 \n",
            "Train Loss: 0.92\n",
            "Accuracy: 94.53%\n",
            "\n",
            "Epoch 0, Iteration 300 \n",
            "Train Loss: 1.34\n",
            "Accuracy: 90.62%\n",
            "\n",
            "Epoch 0, Iteration 325 \n",
            "Train Loss: 1.10\n",
            "Accuracy: 93.75%\n",
            "\n",
            "Epoch 0, Iteration 350 \n",
            "Train Loss: 1.14\n",
            "Accuracy: 92.97%\n",
            "\n",
            "Epoch 0, Iteration 375 \n",
            "Train Loss: 0.99\n",
            "Accuracy: 95.31%\n",
            "\n",
            "Epoch 0, Iteration 400 \n",
            "Train Loss: 0.94\n",
            "Accuracy: 92.97%\n",
            "\n",
            "Epoch 0, Iteration 425 \n",
            "Train Loss: 0.70\n",
            "Accuracy: 96.88%\n",
            "\n",
            "Epoch 0, Iteration 450 \n",
            "Train Loss: 1.08\n",
            "Accuracy: 92.97%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy(data_loader, net, num_steps):\n",
        "  with torch.no_grad():\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    net.eval()\n",
        "\n",
        "    data_loader = iter(data_loader)\n",
        "    for data, targets in data_loader:\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "      spk_rec, _ = net(data)\n",
        "\n",
        "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
        "      total += spk_rec.size(1)\n",
        "\n",
        "  return acc/total\n",
        "\n",
        "print(f\"Trained decay rate of the first layer: {net.lif1.beta:.3f}\\n\")\n",
        "print(f\"Trained decay rates of the second layer: {net.lif2.beta}\")\n",
        "print(f\"Test set accuracy: {test_accuracy(test_loader, net, num_steps)*100:.3f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8S_XNnKxqzq",
        "outputId": "6127ac71-22fc-42aa-b3b0-dc13d8da3f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained decay rate of the first layer: 0.977\n",
            "\n",
            "Trained decay rates of the second layer: Parameter containing:\n",
            "tensor([0.1856, 0.2179, 0.1685, 0.1878, 0.1592, 0.7038, 0.5146, 0.5724, 0.6376,\n",
            "        0.7811], requires_grad=True)\n",
            "Test set accuracy: 94.660%\n"
          ]
        }
      ]
    }
  ]
}